import torch 
import time
import numpy as np
import cv2
import torchaudio
from collections import OrderedDict


def load_ema_weights(model, model_dir):
    checkpoint = torch.load(model_dir, map_location=device)

    #print(len(checkpoint['model']), len(checkpoint['ema_weights']))
    try:
      dic_ema = {}
      for (key, tensor) in zip(checkpoint['model'].keys(), checkpoint['ema_weights']):
          dic_ema[key] = tensor
      model.load_state_dict(dic_ema)
    except:
      dic_ema = {}
      i=0
      for (key, tensor) in zip(checkpoint['model'].keys(), checkpoint['model'].values()):
          if tensor.requires_grad:
              dic_ema[key]=checkpoint['ema_weights'][i]
              i=i+1
          else:
              dic_ema[key]=tensor     
      model.load_state_dict(dic_ema)
    return model

def load_weights(model, model_dir):
    checkpoint = torch.load(model_dir, map_location=device)

    #print(len(checkpoint['model']), len(checkpoint['ema_weights']))
    try:
      dic_ema = {}
      for (key, tensor) in zip(checkpoint['model'].keys(), checkpoint['weights']):
          dic_ema[key] = tensor
      model.load_state_dict(dic_ema)
    except:
      dic_ema = {}
      i=0
      for (key, tensor) in zip(checkpoint['model'].keys(), checkpoint['model'].values()):
          if tensor.requires_grad:
              dic_ema[key]=checkpoint['weights'][i]
              i=i+1
          else:
              dic_ema[key]=tensor     
      model.load_state_dict(dic_ema)
    return model

def do_istft(data, win_size=2048, hop_size=512, device="cuda"):
    window=torch.hamming_window(window_length=win_size) #this is slow! consider optimizing
    window=window.to(device)
    data=data.permute(0,3,2,1)
    pred_time=torch.istft(data, win_size, hop_length=hop_size,  window=window, center=False, return_complex=False)
    return pred_time

def remove_high_freqs(noisy, clean=None, f_dim=1025):
    noisy=noisy[:,:,:,0:f_dim] 
    if clean!=None:
        clean=clean[:,:,:,0:f_dim] 
        return noisy, clean
    else:
        return noisy


def do_stft(noisy, clean=None, win_size=2048, hop_size=512, device="cpu", DC=True):
    
    #window_fn = tf.signal.hamming_window

    #win_size=args.stft.win_size
    #hop_size=args.stft.hop_size
    window=torch.hamming_window(window_length=win_size)
    window=window.to(noisy.device)
    noisy=torch.cat((noisy, torch.zeros(noisy.shape[0],win_size).to(noisy.device)),1)
    stft_signal_noisy=torch.stft(noisy, win_size, hop_length=hop_size,window=window,center=False,return_complex=False)
    stft_signal_noisy=stft_signal_noisy.permute(0,3,2,1)
    #stft_signal_noisy=tf.signal.stft(noisy,frame_length=win_size, window_fn=window_fn, frame_step=hop_size)
    #stft_noisy_stacked=tf.stack( values=[tf.math.real(stft_signal_noisy), tf.math.imag(stft_signal_noisy)], axis=-1)
    
    if clean!=None:

       # stft_signal_clean=tf.signal.stft(clean,frame_length=win_size, window_fn=window_fn, frame_step=hop_size)
        clean=torch.cat((clean, torch.zeros(clean.shape[0],win_size).to(device)),1)
        stft_signal_clean=torch.stft(clean, win_size, hop_length=hop_size,window=window, center=False,return_complex=False)
        stft_signal_clean=stft_signal_clean.permute(0,3,2,1)
        #stft_clean_stacked=tf.stack( values=[tf.math.real(stft_signal_clean), tf.math.imag(stft_signal_clean)], axis=-1)


        if DC:
            return stft_signal_noisy, stft_signal_clean
        else:
            return stft_signal_noisy[...,1:], stft_signal_clean[...,1:]
    else:

        if DC:
            return stft_signal_noisy
        else:
            return stft_signal_noisy[...,1:]

#def mel_spectrogram(y, n_fft, num_mels, sampling_rate, hop_size, win_size, fmin, fmax, center=False):
#    if torch.min(y) < -1.:
#        print('min value is ', torch.min(y))
#    if torch.max(y) > 1.:
#        print('max value is ', torch.max(y))
#
#    global mel_basis, hann_window
#    if fmax not in mel_basis:
#        mel = librosa_mel_fn(sampling_rate, n_fft, num_mels, fmin, fmax)
#        mel_basis[str(fmax)+'_'+str(y.device)] = torch.from_numpy(mel).float().to(y.device)
#        hann_window[str(y.device)] = torch.hann_window(win_size).to(y.device)
#
#    y = torch.nn.functional.pad(y.unsqueeze(1), (int((n_fft-hop_size)/2), int((n_fft-hop_size)/2)), mode='reflect')
#    y = y.squeeze(1)
#
#    spec = torch.stft(y, n_fft, hop_length=hop_size, win_length=win_size, window=hann_window[str(y.device)],
#                      center=center, pad_mode='reflect', normalized=False, onesided=True)
#
#    spec = torch.sqrt(spec.pow(2).sum(-1)+(1e-9))
#
#    spec = torch.matmul(mel_basis[str(fmax)+'_'+str(y.device)], spec)
#    spec = spectral_normalize_torch(spec)
#
#    return spec 
def computeSNR(ref,x): #check shapes
    # Signal-to-noise ratio for torch tensors
    ref_pow = (ref**2).mean(-1) + np.finfo('float32').eps
    dif_pow = ((x - ref)**2).mean(-1) + np.finfo('float32').eps
    snr_val = 10 * torch.log10(ref_pow / dif_pow)
    snr_val= torch.sum(snr_val,axis=0)
    return snr_val

def computeLSD(y,y_g): #check!!!
    yF=do_stft(y,win_size=2048, hop_size=512)
    ygF=do_stft(y_g, win_size=2048, hop_size=512)
    yF=torch.sqrt(yF[:,0,:,:]**2 +yF[:,1,:,:]**2)
    ygF=torch.sqrt(ygF[:,0,:,:]**2 +ygF[:,1,:,:]**2)
    Sy = torch.log10(torch.abs(yF)**2 + 1e-8)
    Syg = torch.log10(torch.abs(ygF)**2 + 1e-8)
    lsd = torch.sum(torch.mean(torch.sqrt(torch.mean((Sy-Syg)**2 + 1e-8, axis=2)), axis=1), axis=0)

    return lsd

def computeHFLSD(y,y_g, fc,fs): #check!!!
    index=int((fc*2048)/fs)
    yF=do_stft(y,win_size=2048, hop_size=512)
    ygF=do_stft(y_g, win_size=2048, hop_size=512)
    yF=torch.sqrt(yF[:,0,:,index:-1]**2 +yF[:,1,:,index:-1]**2)
    ygF=torch.sqrt(ygF[:,0,:,index:-1]**2 +ygF[:,1,:,index:-1]**2)
    Sy = torch.log10(torch.abs(yF)**2 + 1e-8)
    Syg = torch.log10(torch.abs(ygF)**2 + 1e-8)
    lsd = torch.sum(torch.mean(torch.sqrt(torch.mean((Sy-Syg)**2 + 1e-8, axis=2)), axis=1), axis=0)

    return lsd
def computeLFLSD(y,y_g,fc,fs): #check!!!
    index=int((fc*2048)/fs)
    yF=do_stft(y,win_size=2048, hop_size=512)
    ygF=do_stft(y_g, win_size=2048, hop_size=512)
    yF=torch.sqrt(yF[:,0,:,0:index]**2 +yF[:,1,:,0:index]**2)
    ygF=torch.sqrt(ygF[:,0,:,0:index]**2 +ygF[:,1,:,0:index]**2)
    Sy = torch.log10(torch.abs(yF)**2 + 1e-8)
    Syg = torch.log10(torch.abs(ygF)**2 + 1e-8)
    lsd = torch.sum(torch.mean(torch.sqrt(torch.mean((Sy-Syg)**2 + 1e-8, axis=2)), axis=1), axis=0)

    return lsd
  
#def generate_images_from_spec(spec):
#    spec=spec.permute(2,1,0)
#    spec=spec.unsqueeze(0)
#    cpx=spec.cpu().detach().numpy()
#    spectro=np.clip((np.flipud(np.transpose(10*np.log10(np.sqrt(np.power(cpx[...,0],2)+np.power(cpx[...,1],2)))))+30)/50,0,1)
#    cmap=cv2.COLORMAP_JET
#    spectro = np.array((1-spectro)* 255, dtype = np.uint8)
#    spectro = cv2.applyColorMap(spectro, cmap)
#    return np.flipud(np.fliplr(spectro))
def generate_images(audio):
    audio=audio.cpu()
    audio=audio.unsqueeze(0)
    cpx=do_stft(audio, win_size=1025, hop_size=256)
    cpx=cpx.permute(0,3,2,1)
    cpx=cpx.cpu().detach().numpy()
    spectro=np.clip((np.flipud(np.transpose(10*np.log10(np.sqrt(np.power(cpx[...,0],2)+np.power(cpx[...,1],2)))))+30)/50,0,1)
    cmap=cv2.COLORMAP_JET
    spectro = np.array((1-spectro)* 255, dtype = np.uint8)
    spectro = cv2.applyColorMap(spectro, cmap)
    return np.flipud(np.fliplr(spectro))

def generate_images_Amat(Amat):
    lenamats=len(Amat) 
    for i in range(lenamats):
        att=Amat[i].cpu().detach().numpy()
        att=np.clip((10*np.log10(att+1e-8)+40)/20, 0,1)
        cmap=cv2.COLORMAP_JET
        att = np.array((1-att)* 255, dtype = np.uint8)
        att = cv2.applyColorMap(att, cmap)
        if i==0:
             res=att
        else:
             res=np.concatenate((res,att), axis=0)
    return res
def generate_images_from_spec_mag(CQTmat):
    CQTmat=CQTmat.permute(0,3,2,1)
    
    for i in range(CQTmat.shape[0]):
        mag=CQTmat[i].cpu().detach().numpy()
        mag=mag.squeeze(2)
        mag=np.clip(mag, 0, None)
        spectro=np.clip((np.flipud(np.transpose(10*np.log10(mag+1e-8)))+30)/50,0,1)
        cmap=cv2.COLORMAP_JET
        spectro = np.array((1-spectro)* 255, dtype = np.uint8)
        spectro = cv2.applyColorMap(spectro, cmap)
        o= np.flipud(np.fliplr(spectro))
        if i==0:
             res=o
        else:
             res=np.concatenate((res,o), axis=0)
    return res
def generate_images_from_cpxspec(CQTmat):
    CQTmat=CQTmat.squeeze(1)
    CQTmat=CQTmat.permute(0,2,1,3)
    
    for i in range(CQTmat.shape[0]):
        cpx=CQTmat[i].cpu().detach().numpy()
        spectro=np.clip((np.flipud(np.transpose(10*np.log10(np.sqrt(np.power(cpx[...,0],2)+np.power(cpx[...,1],2)))))+30)/50,0,1)
        cmap=cv2.COLORMAP_JET
        spectro = np.array((1-spectro)* 255, dtype = np.uint8)
        spectro = cv2.applyColorMap(spectro, cmap)
        #print(spectro.shape)
        o= np.flipud(np.fliplr(spectro))
        if i==0:
             res=o
        else:
             res=np.concatenate((res,o), axis=0)
    return res
def generate_images_from_cqt(CQTmat):
    CQTmat=CQTmat.permute(0,3,2,1)
    
    for i in range(CQTmat.shape[0]):
        cpx=CQTmat[i].cpu().detach().numpy()
        spectro=np.clip((np.flipud(np.transpose(10*np.log10(np.sqrt(np.power(cpx[...,0],2)+np.power(cpx[...,1],2)))))+30)/50,0,1)
        cmap=cv2.COLORMAP_JET
        spectro = np.array((1-spectro)* 255, dtype = np.uint8)
        spectro = cv2.applyColorMap(spectro, cmap)
        o= np.flipud(np.fliplr(spectro))
        if i==0:
             res=o
        else:
             res=np.concatenate((res,o), axis=0)
    return res
#def generate_images_cqt(audio, CQTransform):
#    audio=audio.unsqueeze(0)
#    cpx=CQTransform.fwd(audio)
#    cpx=cpx.permute(0,3,2,1)
#    cpx=cpx.cpu().detach().numpy()
#    spectro=np.clip((np.flipud(np.transpose(10*np.log10(np.sqrt(np.power(cpx[...,0],2)+np.power(cpx[...,1],2)))))+30)/50,0,1)
#    cmap=cv2.COLORMAP_JET
#    spectro = np.array((1-spectro)* 255, dtype = np.uint8)
#    spectro = cv2.applyColorMap(spectro, cmap)
#    return np.flipud(np.fliplr(spectro))

def apply_nlds(x):
    #H=[0, 1.4847, 0, -1.4449, 0, 2.4713, 0, -2.4234, 0, 0.9158, 0];  #FEXP!  Analytical and Perceptual Evaluation of Nonlinear Devices for Virtual Bass System, Nay Oo , and Woon-Seng Gan
    #x1=torch.zeros_like(x)
    #for n in range(1,len(H)):
    #    x1=x1+H[n]*x**(n)
    #HWR, RELU is the same

    x1=torch.nn.functional.tanh(x)
    x2=torch.nn.functional.relu(x)
    

    return torch.stack((x1,x2), dim=1)
